{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GridWorld\n",
    "## A Project Demonstrating the Techniques of Dynamic Programming\n",
    "\n",
    "The gridworld is a two dimensional grid upon which the agent lives.  \n",
    "At each timestep, the agent must travel to any of the cells surrounding the one it currently resides in.  \n",
    "Depending on the cell the agent moves to, it recieves a numerical reward, which it tries to maximise.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start off by importing some packages and defining the environment - that is, the grid -  itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "eps = 1e-9\n",
    "\n",
    "class Action(Enum):\n",
    "    N, S, E, W = (10 ** i for i in range(4))\n",
    "\n",
    "\n",
    "class GridWorld:\n",
    "    \"\"\" A test reinforcement learning environment where\n",
    "        the agent is to learn to navigate around a grid\n",
    "        with rewards determined by the tile it lands on\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, rows, cols):\n",
    "        self.rows = rows\n",
    "        self.cols = cols\n",
    "        self.state = (0, 0)\n",
    "\n",
    "        self.stateReward = np.zeros((rows, cols), np.float64)\n",
    "        posState = (np.random.randint(0, rows), np.random.randint(0, cols))\n",
    "        negState = (np.random.randint(0, rows), np.random.randint(0, cols))\n",
    "        while posState == negState:\n",
    "            negState = (np.random.randint(0, rows), np.random.randint(0, cols))\n",
    "        self.stateReward[posState] = 1\n",
    "        self.stateReward[negState] = -1\n",
    "\n",
    "    def afterAction(self, state, action):\n",
    "        \"\"\" Returns the state that would be transitioned to\n",
    "            after given action would be executed from the\n",
    "            given position\n",
    "        \"\"\"\n",
    "\n",
    "        if action == Action.N:\n",
    "            return (max(0, state[0] - 1), state[1])\n",
    "        elif action == Action.S:\n",
    "            return (min(self.rows - 1, state[0] + 1), state[1])\n",
    "        elif action == Action.E:\n",
    "            return (state[0], min(self.cols - 1, state[1] + 1))\n",
    "        elif action == Action.W:\n",
    "            return (state[0], max(0, state[1] - 1))\n",
    "        else:\n",
    "            print('Invalid action.')\n",
    "            return state\n",
    "\n",
    "    def doAction(self, action):\n",
    "        \"\"\" Changes position as per state transition kernel\n",
    "            and returns numerical reward\n",
    "        \"\"\"\n",
    "\n",
    "        self.state = self.afterAction(self.state, action)\n",
    "        return self.stateReward[self.state]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the environment's definition is ready, we can initialize it with some previously chosen parameters.  \n",
    "We also set up whatever hyperparameters our learning algorithm uses.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.]\n",
      " [ 0.  0. -1.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "rows, cols, gamma = 5, 5, 0.5\n",
    "gw = GridWorld(rows, cols)\n",
    "print(gw.stateReward)  # The rewards at different cells - the agent is not privy to this information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Policy Evaluation and Iteration.\n",
    "\n",
    "We can now perform policy evaluation and iteration. Policy evaluation aims to find out how good our policy is.  \n",
    "We know a policy is better than another when it has a higher v_pi(s) for all s. In accordance with this,  \n",
    "policy evaluation finds v_pi iteratively, getting a closer estimate with each iteration using the Bellman equations.  \n",
    "Once we have v_pi, we can easily get a new, improved policy by acting greedily upon it. In turn we can evaluate  \n",
    "this new policy and repeat. Eventually, we arrive at the optimal policy. This is called policy iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "policyValues = np.zeros((rows, cols), np.float64)  # The policy - information the agent uses to decide what to do.\n",
    "\n",
    "# This outer loop does policy iteration - once the inner loop finds v_pi it updates the policy to act greedily upon it.\n",
    "# This guarantees improvement until we achieve an optimal policy.\n",
    "while True:\n",
    "    values = np.zeros((rows, cols), np.float64)\n",
    "\n",
    "    # This inner loop does policy evaluation - when the control breaks out updatedValues contains v_pi.\n",
    "    while True:\n",
    "        updatedValues = np.zeros((rows, cols), np.float64)\n",
    "\n",
    "        it = np.nditer(updatedValues, flags=['multi_index'], op_flags=['writeonly'])\n",
    "        for updatedValue in it:\n",
    "            possibleNextStates = [gw.afterAction(it.multi_index, action) for _, action in Action.__members__.items()]\n",
    "            maxValue = max([policyValues[possibleNextState] for possibleNextState in possibleNextStates])\n",
    "            nextStates = list(filter(lambda s: np.abs(policyValues[s] - maxValue) <= eps, possibleNextStates))\n",
    "\n",
    "            for nextState in nextStates:\n",
    "                updatedValue += values[nextState]\n",
    "            updatedValue *= gamma / len(nextStates)\n",
    "            updatedValue += gw.stateReward[it.multi_index]\n",
    "\n",
    "        if (np.abs(values - updatedValues) <= eps).all():  # This becomes True when the values have converged.\n",
    "            break\n",
    "\n",
    "        values = np.copy(updatedValues)\n",
    "\n",
    "    if (np.abs(policyValues - updatedValues) <= eps).all():  # This becomes True when the policy has converged.\n",
    "        break\n",
    "\n",
    "    policyValues = np.copy(updatedValues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now visualise the resulting values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cthresh = np.max(policyValues)\n",
    "plt.imshow(values, cmap='coolwarm', vmin=-cthresh, vmax=cthresh)  # A visualization of how good the agent thinks each cell is.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And also visualise the policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['↘' '↘' '↘' '↓' '↙']\n",
      " ['↘' '↘' '↘' '↓' '↙']\n",
      " ['→' '→' '→' '✣' '←']\n",
      " ['↗' '↗' '↗' '↑' '↖']\n",
      " ['↗' '↑' '↗' '↑' '↖']]\n"
     ]
    }
   ],
   "source": [
    "policy = np.zeros((rows, cols), '<U1')\n",
    "it = np.nditer(policyValues, flags=['multi_index'], op_flags=['writeonly'])\n",
    "for _ in it:\n",
    "    possibleNextStates = [gw.afterAction(it.multi_index, action) for _, action in Action.__members__.items()]\n",
    "    maxValue = max([policyValues[possibleNextState] for possibleNextState in possibleNextStates])\n",
    "\n",
    "    actionCode = 0\n",
    "    for _, action in Action.__members__.items():\n",
    "        if np.abs(policyValues[gw.afterAction(it.multi_index, action)] - maxValue) <= eps:\n",
    "            actionCode += action._value_\n",
    "\n",
    "    if actionCode == 1:\n",
    "        policy[it.multi_index] = '↑'\n",
    "    elif actionCode == 10:\n",
    "        policy[it.multi_index] = '↓'\n",
    "    elif actionCode == 100:\n",
    "        policy[it.multi_index] = '→'\n",
    "    elif actionCode == 1000:\n",
    "        policy[it.multi_index] = '←'\n",
    "    elif actionCode == 11:\n",
    "        policy[it.multi_index] = '↕'\n",
    "    elif actionCode == 1100:\n",
    "        policy[it.multi_index] = '↔'\n",
    "    elif actionCode == 1001:\n",
    "        policy[it.multi_index] = '↖'     \n",
    "    elif actionCode == 101:\n",
    "        policy[it.multi_index] = '↗'     \n",
    "    elif actionCode == 110:\n",
    "        policy[it.multi_index] = '↘'     \n",
    "    elif actionCode == 1010:\n",
    "        policy[it.multi_index] = '↙'\n",
    "    elif actionCode == 1111:\n",
    "        policy[it.multi_index] = '✣'   \n",
    "    else:\n",
    "        policy[it.multi_index] = '?'\n",
    "\n",
    "print(policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Value Iteration\n",
    "\n",
    "Policy iteration involved waiting for policy evaluation to converge over many iterations, then iterating  \n",
    "to the next policy. In value iteration, we only do one iteration of policy evaluation before moving on to\n",
    "the next policy. This still works as even a single iteration gives us an improvement over the previous  \n",
    "and can be faster than policy iteration since it can take may iteration to get from a reasonably good\n",
    "estimate of v_pi to the optimal one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = np.zeros((rows, cols), np.float64)\n",
    "\n",
    "# Each iteration of this loop improves the policy a little.\n",
    "while True:\n",
    "    updatedValues = np.zeros((rows, cols), np.float64)\n",
    "\n",
    "    it = np.nditer(updatedValues, flags=['multi_index'], op_flags=['writeonly'])\n",
    "    for updatedValue in it:\n",
    "        possibleNextStates = [gw.afterAction(it.multi_index, action) for _, action in Action.__members__.items()]\n",
    "        maxValue = max([values[possibleNextState] for possibleNextState in possibleNextStates])\n",
    "        nextStates = list(filter(lambda s: np.abs(values[s] - maxValue) <= eps, possibleNextStates))\n",
    "\n",
    "        for nextState in nextStates:\n",
    "            updatedValue += values[nextState]\n",
    "        updatedValue *= gamma / len(nextStates)\n",
    "        updatedValue += gw.stateReward[it.multi_index]\n",
    "\n",
    "    if (np.abs(values - updatedValues) <= eps).all():  # This becomes True when the policy has converged.\n",
    "        break\n",
    "\n",
    "    values = np.copy(updatedValues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with policy iteration, we will now visualise the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cthresh = np.max(values)\n",
    "plt.imshow(values, cmap='coolwarm', vmin=-cthresh, vmax=cthresh)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, we also visualize the policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['↘' '↘' '↘' '↓' '↙']\n",
      " ['↘' '↘' '↘' '↓' '↙']\n",
      " ['→' '→' '→' '✣' '←']\n",
      " ['↗' '↗' '↗' '↑' '↖']\n",
      " ['↗' '↑' '↗' '↑' '↖']]\n"
     ]
    }
   ],
   "source": [
    "policy = np.zeros((rows, cols), '<U1')\n",
    "it = np.nditer(values, flags=['multi_index'], op_flags=['writeonly'])\n",
    "for _ in it:\n",
    "    possibleNextStates = [gw.afterAction(it.multi_index, action) for _, action in Action.__members__.items()]\n",
    "    maxValue = max([values[possibleNextState] for possibleNextState in possibleNextStates])\n",
    "\n",
    "    actionCode = 0\n",
    "    for _, action in Action.__members__.items():\n",
    "        if np.abs(values[gw.afterAction(it.multi_index, action)] - maxValue) <= eps:\n",
    "            actionCode += action._value_\n",
    "\n",
    "    if actionCode == 1:\n",
    "        policy[it.multi_index] = '↑'\n",
    "    elif actionCode == 10:\n",
    "        policy[it.multi_index] = '↓'\n",
    "    elif actionCode == 100:\n",
    "        policy[it.multi_index] = '→'\n",
    "    elif actionCode == 1000:\n",
    "        policy[it.multi_index] = '←'\n",
    "    elif actionCode == 11:\n",
    "        policy[it.multi_index] = '↕'\n",
    "    elif actionCode == 1100:\n",
    "        policy[it.multi_index] = '↔'\n",
    "    elif actionCode == 1001:\n",
    "        policy[it.multi_index] = '↖'     \n",
    "    elif actionCode == 101:\n",
    "        policy[it.multi_index] = '↗'     \n",
    "    elif actionCode == 110:\n",
    "        policy[it.multi_index] = '↘'     \n",
    "    elif actionCode == 1010:\n",
    "        policy[it.multi_index] = '↙'\n",
    "    elif actionCode == 1111:\n",
    "        policy[it.multi_index] = '✣'   \n",
    "    else:\n",
    "        policy[it.multi_index] = '?'\n",
    "\n",
    "print(policy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
